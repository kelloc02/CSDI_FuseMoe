{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "216b030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def hours_to_HHMM(hours: float) -> str:\n",
    "    total_minutes = int(round(hours * 60))\n",
    "    hh = total_minutes // 60\n",
    "    mm = total_minutes % 60\n",
    "    return f\"{hh:02d}:{mm:02d}\"\n",
    "\n",
    "def is_valid_number(x) -> bool:\n",
    "    try:\n",
    "        return np.isfinite(x)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def build_default_param_names(K: int):\n",
    "    base = [\n",
    "        \"HR\",\"NISysABP\",\"NIDiasABP\",\"NIMAP\",\"RespRate\",\"Temp\",\"Urine\",\n",
    "        \"BUN\",\"Creatinine\",\"Glucose\",\"HCO3\",\"HCT\",\"Platelets\",\"Mg\",\"K\",\"Na\",\"WBC\",\n",
    "        \"GCS\",\"FiO2\",\"SpO2\",\"PaO2\",\"PaCO2\",\"pH\",\"Lactate\",\"Bilirubin\",\"ALT\",\"AST\",\n",
    "        \"Albumin\",\"HGB\",\"RBC\"\n",
    "    ]\n",
    "    if K <= len(base):\n",
    "        return base[:K]\n",
    "    return base + [f\"Param_{i:02d}\" for i in range(len(base)+1, K+1)]\n",
    "\n",
    "def write_one_sample_txt(sample: dict, out_dir: str, param_names=None):\n",
    "    \"\"\"\n",
    "    必备字段：\n",
    "        hadm_id, ts_tt(T,), irg_ts(T,K), irg_ts_mask(T,K) (1=观测, 0=缺失)\n",
    "    规则：\n",
    "        - 只写观测到的条目：mask==1 且值为有限数；否则“跳过该行”（不写 -1）\n",
    "        - 参数名与列索引保持一致，不会错位\n",
    "    \"\"\"\n",
    "    stay_id = int(sample.get(\"stay_id\"))\n",
    "    ts_tt  = np.asarray(sample[\"ts_tt\"])                 # (T,)\n",
    "    X      = np.asarray(sample[\"irg_ts\"])                # (T,K)\n",
    "    M      = np.asarray(sample[\"irg_ts_mask\"]).astype(int)  # (T,K)\n",
    "\n",
    "    assert ts_tt.ndim == 1\n",
    "    assert X.ndim == 2 and M.ndim == 2 and X.shape == M.shape\n",
    "    T, K = X.shape\n",
    "\n",
    "    # 参数名就位（严格按列索引映射）\n",
    "    if param_names is None:\n",
    "        param_names = build_default_param_names(K)\n",
    "    elif len(param_names) != K:\n",
    "        # 保证一一对应（不匹配时按列裁剪/补齐，不会改变索引语义）\n",
    "        if len(param_names) > K:\n",
    "            param_names = param_names[:K]\n",
    "        else:\n",
    "            param_names = param_names + [f\"Param_{i:02d}\" for i in range(len(param_names)+1, K+1)]\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    out_path = os.path.join(out_dir, f\"{stay_id}.txt\")\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"Time,Parameter,Value\\n\")\n",
    "        f.write(f\"00:00,RecordID,{stay_id}\\n\")\n",
    "\n",
    "        for t in range(T):\n",
    "            hhmm = hours_to_HHMM(float(ts_tt[t]))\n",
    "            # 仅写入“观测且有效”的条目；缺失的（mask==0）直接不写\n",
    "            for k in range(K):\n",
    "                if M[t, k] == 1 and is_valid_number(X[t, k]):\n",
    "                    # 注意：真实值允许为负（如标准化后的负数），不会被删除\n",
    "                    f.write(f\"{hhmm},{param_names[k]},{X[t, k]}\\n\")\n",
    "\n",
    "    return out_path\n",
    "\n",
    "def convert_pkl_to_csdi_txt(pkl_path: str, out_dir: str, sample_limit: int=None, param_names=None):\n",
    "    with open(pkl_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    n = len(data) if sample_limit is None else min(len(data), sample_limit)\n",
    "    out_files = []\n",
    "    for i in range(n):\n",
    "        s = data[i]\n",
    "        if all(k in s for k in [\"ts_tt\", \"irg_ts\", \"irg_ts_mask\"]):\n",
    "            out_files.append(write_one_sample_txt(s, out_dir, param_names=param_names))\n",
    "    return out_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9d68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "导出完成，共 5270 个 txt。示例：['/playpen-shared/kechengli/workspace/Fusemoe/CSDI-main/data/ihm_data_val/36850695.txt', '/playpen-shared/kechengli/workspace/Fusemoe/CSDI-main/data/ihm_data_val/36250312.txt', '/playpen-shared/kechengli/workspace/Fusemoe/CSDI-main/data/ihm_data_val/33028574.txt']\n"
     ]
    }
   ],
   "source": [
    "# # === 使用示例 ===\n",
    "# PKL_PATH = r\"/playpen-shared/kechengli/workspace/dataset/mimiciv_pkl/test_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\"\n",
    "# OUT_DIR = r\"/playpen-shared/kechengli/workspace/Fusemoe/CSDI-main/data/ihm_data_test\"\n",
    "\n",
    "# # 可选：自定义 30 个参数名（顺序需与你的 irg_ts 列维度一致）\n",
    "# custom_param_names = [\n",
    "#     \"HR\",\"NISysABP\",\"NIDiasABP\",\"NIMAP\",\"RespRate\",\"Temp\",\"Urine\",\n",
    "#     \"BUN\",\"Creatinine\",\"Glucose\",\"HCO3\",\"HCT\",\"Platelets\",\"Mg\",\"K\",\"Na\",\"WBC\",\n",
    "#     \"GCS\",\"FiO2\",\"SpO2\",\"PaO2\",\"PaCO2\",\"pH\",\"Lactate\",\"Bilirubin\",\"ALT\",\"AST\",\n",
    "#     \"Albumin\",\"HGB\",\"RBC\"\n",
    "# ]  # 若与你的 30 维不一致，会自动补/裁切\n",
    "\n",
    "# files = convert_pkl_to_csdi_txt(\n",
    "#     PKL_PATH,\n",
    "#     OUT_DIR,\n",
    "#     sample_limit=None,            # 改为 10 可先导出 10 个试试\n",
    "#     param_names=custom_param_names\n",
    "# )\n",
    "# print(f\"导出完成，共 {len(files)} 个 txt。示例：{files[:3]}\")\n",
    "\n",
    "\n",
    "# === 使用示例 ===\n",
    "PKL_PATH = r\"/playpen-shared/kechengli/workspace/dataset/mimiciv_pkl/val_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\"\n",
    "OUT_DIR = r\"/playpen-shared/kechengli/workspace/Fusemoe/CSDI-main/data/ihm_data_val\"\n",
    "\n",
    "# 可选：自定义 30 个参数名（顺序需与你的 irg_ts 列维度一致）\n",
    "custom_param_names = [\n",
    "    \"HR\",\"NISysABP\",\"NIDiasABP\",\"NIMAP\",\"RespRate\",\"Temp\",\"Urine\",\n",
    "    \"BUN\",\"Creatinine\",\"Glucose\",\"HCO3\",\"HCT\",\"Platelets\",\"Mg\",\"K\",\"Na\",\"WBC\",\n",
    "    \"GCS\",\"FiO2\",\"SpO2\",\"PaO2\",\"PaCO2\",\"pH\",\"Lactate\",\"Bilirubin\",\"ALT\",\"AST\",\n",
    "    \"Albumin\",\"HGB\",\"RBC\"\n",
    "]  # 若与你的 30 维不一致，会自动补/裁切\n",
    "\n",
    "files = convert_pkl_to_csdi_txt(\n",
    "    PKL_PATH,\n",
    "    OUT_DIR,\n",
    "    sample_limit=None,            # 改为 10 可先导出 10 个试试\n",
    "    param_names=custom_param_names\n",
    ")\n",
    "print(f\"导出完成，共 {len(files)} 个 txt。示例：{files[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682dd5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================\n",
      "Processing: train_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\n",
      "Input:  /playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_csdi/train_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\n",
      "Output: /playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_fuse/train_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\n",
      "Loading original file...\n",
      "Converting arrays...\n",
      "Saving Python3.8 compatible pickle...\n",
      "Done! Saved → /playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_fuse/train_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\n",
      "\n",
      "====================\n",
      "Processing: val_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\n",
      "Input:  /playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_csdi/val_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\n",
      "Output: /playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_fuse/val_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\n",
      "Loading original file...\n",
      "Converting arrays...\n",
      "Saving Python3.8 compatible pickle...\n",
      "Done! Saved → /playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_fuse/val_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\n",
      "\n",
      "====================\n",
      "Processing: test_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\n",
      "Input:  /playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_csdi/test_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\n",
      "Output: /playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_fuse/test_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\n",
      "Loading original file...\n",
      "Converting arrays...\n",
      "Saving Python3.8 compatible pickle...\n",
      "Done! Saved → /playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_fuse/test_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\n",
      "\n",
      "All files processed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from collections.abc import Mapping, Sequence\n",
    "\n",
    "# 输入和输出文件夹\n",
    "input_dir = \"/playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_csdi\"\n",
    "output_dir = \"/playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_fuse\"\n",
    "\n",
    "# 需要处理的文件列表\n",
    "files = [\n",
    "    \"train_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\",\n",
    "    \"val_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\",\n",
    "    \"test_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\"\n",
    "]\n",
    "\n",
    "def convert(obj):\n",
    "    \"\"\"Recursively convert numpy arrays to Python lists → then back to numpy arrays\"\"\"\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return np.array(obj.tolist())  # 解除 numpy 内部引用\n",
    "    \n",
    "    elif isinstance(obj, Mapping):\n",
    "        return {k: convert(v) for k, v in obj.items()}\n",
    "    \n",
    "    elif isinstance(obj, Sequence) and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        return [convert(x) for x in obj]\n",
    "\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "# =============================\n",
    "#        主循环处理\n",
    "# =============================\n",
    "for filename in files:\n",
    "    input_path = os.path.join(input_dir, filename)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    print(f\"\\n====================\")\n",
    "    print(f\"Processing: {filename}\")\n",
    "    print(f\"Input:  {input_path}\")\n",
    "    print(f\"Output: {output_path}\")\n",
    "\n",
    "    # 加载\n",
    "    print(\"Loading original file...\")\n",
    "    with open(input_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    # 转换\n",
    "    print(\"Converting arrays...\")\n",
    "    clean_data = convert(data)\n",
    "\n",
    "    # 保存\n",
    "    print(\"Saving Python3.8 compatible pickle...\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    with open(output_path, \"wb\") as f:\n",
    "        pickle.dump(clean_data, f, protocol=4)\n",
    "\n",
    "    print(f\"Done! Saved → {output_path}\")\n",
    "\n",
    "print(\"\\nAll files processed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58689f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing train_ihm-48-cxr-notes-ecg-missingInd_stays.pkl ===\n",
      "Loading /playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_csdi/train_ihm-48-cxr-notes-ecg-missingInd_stays.pkl...\n",
      "Converting to safe JSON+NPY...\n",
      "Saved intermediate data to /playpen-shared/kechengli/workspace/dataset/tmp1/train_ihm-48-cxr-notes-ecg-missingInd_stays\n",
      "\n",
      "=== Processing val_ihm-48-cxr-notes-ecg-missingInd_stays.pkl ===\n",
      "Loading /playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_csdi/val_ihm-48-cxr-notes-ecg-missingInd_stays.pkl...\n",
      "Converting to safe JSON+NPY...\n",
      "Saved intermediate data to /playpen-shared/kechengli/workspace/dataset/tmp1/val_ihm-48-cxr-notes-ecg-missingInd_stays\n",
      "\n",
      "=== Processing test_ihm-48-cxr-notes-ecg-missingInd_stays.pkl ===\n",
      "Loading /playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_csdi/test_ihm-48-cxr-notes-ecg-missingInd_stays.pkl...\n",
      "Converting to safe JSON+NPY...\n",
      "Saved intermediate data to /playpen-shared/kechengli/workspace/dataset/tmp1/test_ihm-48-cxr-notes-ecg-missingInd_stays\n",
      "\n",
      "All files successfully converted!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "\n",
    "input_dir = \"/playpen-shared/kechengli/workspace/dataset/mimiciv_after_diff_csdi\"\n",
    "tmp_root = \"/playpen-shared/kechengli/workspace/dataset/tmp1\"\n",
    "\n",
    "files = [\n",
    "    \"train_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\",\n",
    "    \"val_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\",\n",
    "    \"test_ihm-48-cxr-notes-ecg-missingInd_stays.pkl\"\n",
    "]\n",
    "\n",
    "os.makedirs(tmp_root, exist_ok=True)\n",
    "\n",
    "def to_python_scalar(x):\n",
    "    if isinstance(x, np.generic):  # numpy 标量\n",
    "        return x.item()            # 转成 Python int/float/bool\n",
    "    return x\n",
    "\n",
    "\n",
    "def save_obj(obj, prefix, save_dir):\n",
    "    # numpy array -> npy file\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        np.save(os.path.join(save_dir, prefix + \".npy\"), obj)\n",
    "        return {\"__type__\": \"npy\", \"path\": prefix + \".npy\"}\n",
    "\n",
    "    # numpy scalar -> python scalar\n",
    "    if isinstance(obj, np.generic):\n",
    "        return to_python_scalar(obj)\n",
    "\n",
    "    # dict\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: save_obj(v, f\"{prefix}_{k}\", save_dir) for k, v in obj.items()}\n",
    "\n",
    "    # list/tuple\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return [save_obj(v, f\"{prefix}_{i}\", save_dir) for i, v in enumerate(obj)]\n",
    "\n",
    "    # already Python-native\n",
    "    return obj\n",
    "\n",
    "\n",
    "for fname in files:\n",
    "    print(f\"\\n=== Processing {fname} ===\")\n",
    "\n",
    "    in_path = os.path.join(input_dir, fname)\n",
    "    tmp_dir = os.path.join(tmp_root, fname.replace(\".pkl\", \"\"))\n",
    "    os.makedirs(tmp_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Loading {in_path}...\")\n",
    "    with open(in_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "\n",
    "    print(\"Converting to safe JSON+NPY...\")\n",
    "    meta = save_obj(data, \"root\", tmp_dir)\n",
    "\n",
    "    meta_path = os.path.join(tmp_dir, \"meta.json\")\n",
    "    with open(meta_path, \"w\") as f:\n",
    "        json.dump(meta, f)\n",
    "\n",
    "    print(f\"Saved intermediate data to {tmp_dir}\")\n",
    "\n",
    "print(\"\\nAll files successfully converted!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bd1e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
